name: Update Events Data on Cloudflare Pages

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:

jobs:
  update-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Main App Repo (to run the script)
        uses: actions/checkout@v4
        with:
          path: main-app

      - name: Checkout Assets Repo (to push the JSON to)
        uses: actions/checkout@v4
        with:
          repository: a2ys/saving-vit
          token: ${{ secrets.ASSETS_REPO_PAT }}
          path: assets-repo

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        working-directory: ./main-app
        run: npm install axios

      - name: Fetch Contentful data, download posters, and create events.json
        working-directory: ./main-app
        env:
          SPACE_ID: ${{ secrets.CONTENTFUL_SPACE_ID }}
          ACCESS_TOKEN: ${{ secrets.CONTENT_DELIVERY_API_ACCESS_TOKEN }}
        run: |
          node <<'EOF'
          const fs = require('fs');
          const path = require('path');
          const axios = require('axios');

          const fetchData = async () => {
            try {
              const spaceId = process.env.SPACE_ID;
              const accessToken = process.env.ACCESS_TOKEN;
              const limit = 100;
              let skip = 0;
              let total;

              let allItems = [];
              let assetIncludes = {};

              // Fetch all events
              do {
                const url = `https://cdn.contentful.com/spaces/${spaceId}/environments/master/entries?access_token=${accessToken}&content_type=event&limit=${limit}&skip=${skip}`;

                const res = await axios.get(url);
                const data = res.data;

                if (data.items && data.items.length > 0) {
                  allItems = allItems.concat(data.items);
                }

                if (data.includes && data.includes.Asset) {
                  data.includes.Asset.forEach(asset => {
                    assetIncludes[asset.sys.id] = asset;
                  });
                }

                if (total === undefined) {
                  total = data.total;
                }

                skip += limit;

                console.log(`üì• Fetched ${allItems.length} / ${total} events...`);

              } while (skip < total);

              // Create posters directory
              const postersDir = path.join('../assets-repo', 'posters');
              if (!fs.existsSync(postersDir)) {
                fs.mkdirSync(postersDir, { recursive: true });
                console.log('üìÅ Created posters directory');
              }

              // Download all poster images
              const assetArray = Object.values(assetIncludes);
              console.log(`\nüì∏ Downloading ${assetArray.length} posters...`);

              for (const asset of assetArray) {
                if (asset.fields && asset.fields.file && asset.fields.file.url) {
                  try {
                    const imageUrl = asset.fields.file.url.startsWith('//')
                      ? `https:${asset.fields.file.url}`
                      : asset.fields.file.url;

                    const fileName = asset.fields.file.fileName;
                    const filePath = path.join(postersDir, fileName);

                    // Download image
                    const response = await axios.get(imageUrl, {
                      responseType: 'arraybuffer',
                      timeout: 30000
                    });

                    fs.writeFileSync(filePath, response.data);
                    console.log(`  ‚úÖ Downloaded: ${fileName}`);

                    // Update asset URL to point to CDN
                    asset.fields.file.url = `/posters/${fileName}`;

                  } catch (err) {
                    console.error(`  ‚ùå Failed to download ${asset.fields.file.fileName}:`, err.message);
                  }
                }
              }

              // Update assetIncludes with modified URLs
              assetIncludes = {};
              assetArray.forEach(asset => {
                assetIncludes[asset.sys.id] = asset;
              });

              const finalData = {
                sys: { type: 'Array' },
                total: allItems.length,
                skip: 0,
                limit: allItems.length,
                items: allItems,
                includes: {
                  Asset: Object.values(assetIncludes)
                }
              };

              const outputPath = '../assets-repo/events.json';
              fs.writeFileSync(outputPath, JSON.stringify(finalData, null, 2));
              console.log(`\n‚úÖ All ${finalData.total} events successfully written to ${outputPath}`);
              console.log(`‚úÖ All posters saved to posters/ directory with updated URLs`);

            } catch (err) {
              console.error('‚ùå Error fetching Contentful data:', err.message);
              process.exit(1);
            }
          };

          fetchData();
          EOF

      - name: Commit and push to Assets Repo
        working-directory: ./assets-repo
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add events.json posters/
          # Exit if there are no changes to commit
          if git diff --staged --quiet; then
            echo "No changes detected. Skipping commit."
            exit 0
          fi
          git commit -m "Update events.json and posters from Contentful"
          git push
